{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "738dfac7-5c97-4b84-be21-335d578ef7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab2bcd7f-20ba-416b-bd19-12eff6cd9800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 12:04:11.750417: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 218.21 MiB (download: 218.21 MiB, generated: 221.83 MiB, total: 440.05 MiB) to /home/harry/tensorflow_datasets/tf_flowers/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harry/Documents/Code/Data_Science/DeepLearning/.venv_tf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Dl Completed...: 100%|██████████████████████████████████████████████████████████████| 5/5 [03:22<00:00, 40.52s/ file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset tf_flowers downloaded and prepared to /home/harry/tensorflow_datasets/tf_flowers/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset,info = tfds.load('tf_flowers',as_supervised=True,with_info=True)\n",
    "dataset_size = info.splits['train'].num_examples #3670\n",
    "class_names = info.features['label'].names #['dandelion','daisy']\n",
    "n_class = info.features['label'].num_classes # 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d4173bb-fc01-4cbc-952e-fe337a3c2cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_raw,valid_set_raw,train_set_raw = tfds.load('tf_flowers',\n",
    "                                                    split = ['train[:10%]','train[10%:25%]','train[25%:]'],\n",
    "                                                    as_supervised = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcb0d0e0-708f-4960-ad65-3f2d6a2cfaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "preprocess = tf.keras.Sequential([\n",
    "    tf.keras.layers.Resizing(height=224,width =224,crop_to_aspect_ratio = True),\n",
    "    tf.keras.layers.Lambda(tf.keras.applications.xception.preprocess_input)\n",
    "])\n",
    "\n",
    "train_set = train_set_raw.map(lambda X,y:(preprocess(X),y))\n",
    "train_set = train_set.shuffle(1000,seed=42).batch(batch_size).prefetch(1)\n",
    "valid_set = valid_set_raw.map(lambda X,y:(preprocess(X),y)).batch(batch_size)\n",
    "test_set  = test_set_raw.map(lambda X,y:(preprocess(X),y)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bfb3094-90d6-459d-8ae9-d0d98dec436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(mode = 'horizontal',seed = 42),\n",
    "    tf.keras.layers.RandomRotation(factor=0.05,seed = 42),\n",
    "    tf.keras.layers.RandomContrast(factor=0.2,seed = 42)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a40bfd2-92d2-4052-8ee5-4cb8abc521ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.xception.Xception(weights='imagenet',include_top = False)\n",
    "avg=tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = tf.keras.layers.Dense(n_class,activation='softmax')(avg)\n",
    "model = tf.keras.Model(inputs=base_model.input,outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4a3626b-199e-4280-8b10-568c3f8dd5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "619648c0-5a65-4bc6-83e8-5b7f19c65ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 12:10:24.600670: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:376] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 3s/step - accuracy: 0.6975 - loss: 1.0837 - val_accuracy: 0.8258 - val_loss: 0.6878\n",
      "Epoch 2/3\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 3s/step - accuracy: 0.9149 - loss: 0.3437 - val_accuracy: 0.8693 - val_loss: 0.5803\n",
      "Epoch 3/3\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 3s/step - accuracy: 0.9299 - loss: 0.2237 - val_accuracy: 0.8693 - val_loss: 0.5896\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1,momentum=0.9)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer= optimizer,metrics=['accuracy'])\n",
    "history = model.fit(train_set,validation_data = valid_set,epochs =3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8c48b4-a929-45a3-8926-d573c57be070",
   "metadata": {},
   "source": [
    "###  Unfreezing some top layers and training again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16ecb3ff-4942-4f83-9de6-5ddb0af84e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[56:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39eb6563-88e2-4859-8069-4023d605d3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 6s/step - accuracy: 0.8798 - loss: 0.3650 - val_accuracy: 0.8802 - val_loss: 0.6065\n",
      "Epoch 2/3\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 5s/step - accuracy: 0.9825 - loss: 0.0579 - val_accuracy: 0.9002 - val_loss: 0.3450\n",
      "Epoch 3/3\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 5s/step - accuracy: 0.9930 - loss: 0.0215 - val_accuracy: 0.9165 - val_loss: 0.2710\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.9)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer= optimizer,metrics=['accuracy'])\n",
    "history = model.fit(train_set,validation_data = valid_set,epochs =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1f935-65c4-44de-8c85-6526810cf018",
   "metadata": {},
   "outputs": [],
   "source": [
    "##classification and localization in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9827e5af-a813-4215-9b67-ce4441fdcfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.xception.Xception(weights='imagenet',include_top = False)\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "class_output = tf.keras.layers.Dense(n_class,activation='softmax')(avg)\n",
    "loc_output = tf.keras.layers.Dense(4)(avg)\n",
    "model =  tf.keras.Model(inputs=base_model.input,outputs=[class_output,loc_output])\n",
    "\n",
    "model.compile(loss=['sparse_categorical_crossentropy','mse'],\n",
    "              loss_weights = [0.8,0.2],\n",
    "              optimizer=optimizer,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a1fc8-437c-4326-96ea-752a85e8a4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
